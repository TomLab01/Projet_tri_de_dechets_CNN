{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TDD_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KVhsu0gMLZKi",
        "QI_f6mWMY1_C",
        "6m29A61GXp40",
        "IznC3UNdUi4W",
        "ZCU3ktCD6zFo",
        "O9-gNpsVGgn2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVhsu0gMLZKi"
      },
      "source": [
        "# Projet Tri de déchets - Classification de déchets sur photos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgCkQ9oGLoOd"
      },
      "source": [
        "Ce notebook permet de réaliser une classification de déchets sur une photo à partir de modèles de CNN entrainés et sauvegardés sur un *Google Drive* connecté."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNGTEZwKLm-6"
      },
      "source": [
        "### Membres de l'équipe :\n",
        "- Amine CHERIF HAOUAT\n",
        "- Tom LABIAUSSE\n",
        "- Cyrine NABI\n",
        "- Pierre OLLIVIER\n",
        "- Selim BEN TURKIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI_f6mWMY1_C"
      },
      "source": [
        "# 0 - Installation des packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhhJFIGT5h-N"
      },
      "source": [
        "Les cellules suivantes doivent être exécutées uniquement si l'utilisateur rencontre des difficultés lors de l'importation des modules en section 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G8DPxl9MK0U"
      },
      "source": [
        "# KERAS\n",
        "!pip install keras==2.4.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oefGV0EDT5c3"
      },
      "source": [
        "# TENSORFLOW\n",
        "!pip install tensorflow==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ItyqGcAT5l1"
      },
      "source": [
        "# PYDRIVE\n",
        "!pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m29A61GXp40"
      },
      "source": [
        "# 1 - Les imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9MLPHaq8EVO"
      },
      "source": [
        "Exécutez les trois cellules suivantes dans l'ordre en suivant les instructions :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSpujIqhEpW-"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        " \n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print(\"-> Authentification Google OK\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNHxcNvPTGgs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path_to_GGDrive = \"/content/gdrive/MyDrive/\"\n",
        "print(\"-> Connexion à Google Drive OK\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub8ssRmsWiVd"
      },
      "source": [
        "from os import listdir\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models, losses, optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "# import matplotlib\n",
        "# import sys\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "from PIL import ImageOps\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "print(\"-> Importations OK.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IznC3UNdUi4W"
      },
      "source": [
        "# 2 - Fonctionnalités diverses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgoZ-FVwGksy"
      },
      "source": [
        "Exécutez les trois cellules suivantes dans l'ordre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqoXnzVdLOk-"
      },
      "source": [
        "def to_percent(x,nb_dec=0):\n",
        "    \"\"\" Donne x sous la forme de pourcentage avec 'nb_dec' chiffres apres la virgule. \"\"\"\n",
        "    if nb_dec == 0:\n",
        "        return(int(100*x))\n",
        "    else:\n",
        "      return( float(int((10**(2+nb_dec))*x))/(10**nb_dec) )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFowrtQrCRW6"
      },
      "source": [
        "def already_exists(file_name,place=\".\"):\n",
        "    \"\"\" Renvoie True si 'file_name' existe à l'emplacement 'place' et False sinon. \"\"\"\n",
        "    existing_files = listdir(place)\n",
        "    for a_file in existing_files:\n",
        "        if a_file == file_name:\n",
        "            return(True)\n",
        "    return(False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3ivlRtZdsEs"
      },
      "source": [
        "def get_dico_pred(nom_image,dico_cnn):\n",
        "    \"\"\" Renvoie un dictionnaire dont les clefs sont les catégories de déchets et les valeurs les prédictions associées. \"\"\"\n",
        "    ## Preprocessing de l'image\n",
        "    img = load_img(path_to_GGDrive + nom_image, target_size=(224, 224))  # Charger l'image\n",
        "    img = img_to_array(img)  # Convertir en tableau numpy de shape (224,224,3)\n",
        "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
        "    img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16\n",
        "    ## Réalise les prédictions pour chaque classifieur binaire\n",
        "    dico_pred = {}\n",
        "    for (name,model_cnn) in dico_cnn.items():\n",
        "        dico_pred[name] = to_percent(model_cnn.predict(img)[0][0],nb_dec=2)\n",
        "    return(dico_pred)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCU3ktCD6zFo"
      },
      "source": [
        "# 3 - Charger les modèles de CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVNJNfER7139"
      },
      "source": [
        "Entrez entre guillemets le nom du dossier contenant les modèles de CNN :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PKbxeZV66Xr"
      },
      "source": [
        "dossier_modeles = \"SAVED_MODELS\"\n",
        "dossier_modeles += \"/\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMRGVr3K_TbE"
      },
      "source": [
        "Entrez entre guillemets le nom des fichiers modèles de CNN :\n",
        "\n",
        "(Si un modèle n'est pas disponible, écrivez seulement deux guillemets consécutifs : \"\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh-w3gz8_Tlj"
      },
      "source": [
        "dico_models = {}\n",
        "dico_models[\"bottle\"] = \"CNN_bottle.h5\"\n",
        "dico_models[\"can\"] = \"CNN_can.h5\"\n",
        "dico_models[\"cup\"] = \"CNN_cup.h5\"\n",
        "dico_models[\"carton\"] = \"CNN_carton.h5\"\n",
        "dico_models[\"cigarette\"] = \"CNN_cigarette.h5\"\n",
        "dico_models[\"mask\"] = \"CNN_mask.h5\"\n",
        "dico_models[\"paper\"] = \"CNN_paper.h5\"\n",
        "dico_models[\"plastic_bag\"] = \"CNN_plastic_bag.h5\"\n",
        "dico_models[\"other_plastic\"] = \"CNN_other_plastic.h5\"\n",
        "dico_models[\"styrofoam\"] = \"CNN_styrofoam.h5\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgfFWkoU___K"
      },
      "source": [
        "Exécutez la cellule ci-dessous pour charger les modèles spécifiés :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzcn477D__uI"
      },
      "source": [
        "dico_cnn = {}\n",
        "for (name,model_name) in dico_models.items():\n",
        "    if model_name != \"\":\n",
        "        if not(already_exists(model_name,place=path_to_GGDrive + dossier_modeles)):\n",
        "            print(\"\"\"Modele \"{0}\" introuvable à l'emplacement '{1}'.\"\"\".format(model_name,path_to_GGDrive + dossier_modeles))\n",
        "        else:\n",
        "            dico_cnn[name] = tf.keras.models.load_model(path_to_GGDrive + dossier_modeles + model_name)\n",
        "            print(\"\"\"Modele \"{0}\" chargé.\"\"\".format(model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9-gNpsVGgn2"
      },
      "source": [
        "# 4 - Réaliser une classification sur une image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCZlMuB07tMM"
      },
      "source": [
        "Entrez entre guillemets le nom de l'image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esoH3jr_7caG"
      },
      "source": [
        "nom_image = \"je_suis_une_image.jpg\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HvKKa0S8Ra_"
      },
      "source": [
        "Visualisez l'image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE_AvNDbPJAh"
      },
      "source": [
        "pil_image =Image.open(path_to_GGDrive + nom_image)\n",
        "plt.imshow(pil_image) ; plt.title(nom_image) ; plt.show()\n",
        "print(\" \")\n",
        "print(\"Largeur : \" + str(pil_image.width) + \" | Hauteur : \" + str(pil_image.height))\n",
        "print(\"Mode : \" + pil_image.mode + \" | Format : \" + pil_image.format)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnfEc6QDDLxZ"
      },
      "source": [
        "Réalisez la classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AQpHhm1HEWb"
      },
      "source": [
        "seuil_1 = 0.5 ; seuil_2 = 0.65\n",
        "dico_pred = get_dico_pred(nom_image,dico_cnn)\n",
        "print(\"\\nPrédictions sur '\" + nom_image + \"' :\")\n",
        "for (name,pred) in dico_pred.items():\n",
        "    if pred < seuil_1:\n",
        "        region = \"NON\"\n",
        "    elif seuil_1 <= pred < seuil_2:\n",
        "        region = \"INDECIS\"\n",
        "    else:\n",
        "       region = \"OUI\"\n",
        "    print(\"- \" + name.upper() + \" : \" + region + \" (\" + str(pred) + \"%)\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}